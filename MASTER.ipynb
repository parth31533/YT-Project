{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ducGHUbdzqKEtZ870bcTyAJIOgqLdCIJ",
      "authorship_tag": "ABX9TyNMT9bQ1SrHClrWNGsDUPtR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parth31533/YT-Project/blob/main/MASTER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vEkYPTK8VhDC",
        "outputId": "2d2f84d4-3f0d-492e-ee55-cff7a3e6d21a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'yt_dlp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a66a7e73367e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myt_dlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myoutube_transcript_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTranscriptsDisabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoTranscriptFound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscovery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yt_dlp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import concurrent.futures\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"  # Replace with your valid YouTube Data API v3 key\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"  # Replace with your AssemblyAI API key\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while True:\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token or len(video_links) >= 2:  # Stop after collecting 2 videos\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    failed_videos = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize transcript fetching\n",
        "        futures = {executor.submit(YouTubeTranscriptApi.get_transcript, link.split(\"v=\")[1]): link for link in video_links}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            link = futures[future]\n",
        "            try:\n",
        "                future.result()  # Will raise an exception if transcript fetch fails\n",
        "                print(f\"Transcript fetched successfully for video: {link}\")\n",
        "            except (TranscriptsDisabled, NoTranscriptFound):\n",
        "                print(f\"Transcript not available for video: {link}\")\n",
        "                failed_videos.append(link)\n",
        "\n",
        "    return failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize audio downloading\n",
        "        futures = {executor.submit(yt_dlp.YoutubeDL(ydl_opts).download, [link]): link for link in video_links}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            link = futures[future]\n",
        "            try:\n",
        "                future.result()  # Will raise an exception if download fails\n",
        "                print(f\"Audio downloaded successfully for video: {link}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Main function to stop after processing two videos\n",
        "def main():\n",
        "    channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # Replace with the actual channel ID\n",
        "\n",
        "    # Step 1: Get the first two video links from the channel\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "\n",
        "    # If less than two videos, stop the process\n",
        "    if len(video_links) < 2:\n",
        "        print(\"Not enough videos found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    failed_videos = fetch_transcripts(video_links)\n",
        "\n",
        "    # Step 3: Download audio files for failed videos\n",
        "    if failed_videos:\n",
        "        download_audio(failed_videos)\n",
        "\n",
        "    # Step 4: Transcribe downloaded audio using AssemblyAI\n",
        "    audio_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize audio transcription\n",
        "        futures = {executor.submit(transcribe_audio, ASSEMBLYAI_API_KEY, audio_file): audio_file for audio_file in audio_files}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            audio_file = futures[future]\n",
        "            transcript = future.result()\n",
        "            if transcript:\n",
        "                print(f\"Transcription completed for {audio_file}: {transcript[:100]}...\")  # Display first 100 chars of the transcript\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yt-dlp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nhz3ptsWC22",
        "outputId": "dfdc1550-5bdd-420c-cc0c-79105a794f26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.12.6-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m163.8/172.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.12.6-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvI1ivbRWISB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4b5632e2-c80d-46fd-ced9-c8171d9b940a",
        "id": "MmTZXyaaWMxy"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'youtube_transcript_api'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1043c8d3ccf5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myt_dlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myoutube_transcript_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTranscriptsDisabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoTranscriptFound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscovery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'youtube_transcript_api'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import concurrent.futures\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"  # Replace with your valid YouTube Data API v3 key\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"  # Replace with your AssemblyAI API key\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while True:\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token or len(video_links) >= 2:  # Stop after collecting 2 videos\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    failed_videos = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize transcript fetching\n",
        "        futures = {executor.submit(YouTubeTranscriptApi.get_transcript, link.split(\"v=\")[1]): link for link in video_links}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            link = futures[future]\n",
        "            try:\n",
        "                future.result()  # Will raise an exception if transcript fetch fails\n",
        "                print(f\"Transcript fetched successfully for video: {link}\")\n",
        "            except (TranscriptsDisabled, NoTranscriptFound):\n",
        "                print(f\"Transcript not available for video: {link}\")\n",
        "                failed_videos.append(link)\n",
        "\n",
        "    return failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize audio downloading\n",
        "        futures = {executor.submit(yt_dlp.YoutubeDL(ydl_opts).download, [link]): link for link in video_links}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            link = futures[future]\n",
        "            try:\n",
        "                future.result()  # Will raise an exception if download fails\n",
        "                print(f\"Audio downloaded successfully for video: {link}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Main function to stop after processing two videos\n",
        "def main():\n",
        "    channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # Replace with the actual channel ID\n",
        "\n",
        "    # Step 1: Get the first two video links from the channel\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "\n",
        "    # If less than two videos, stop the process\n",
        "    if len(video_links) < 2:\n",
        "        print(\"Not enough videos found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    failed_videos = fetch_transcripts(video_links)\n",
        "\n",
        "    # Step 3: Download audio files for failed videos\n",
        "    if failed_videos:\n",
        "        download_audio(failed_videos)\n",
        "\n",
        "    # Step 4: Transcribe downloaded audio using AssemblyAI\n",
        "    audio_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize audio transcription\n",
        "        futures = {executor.submit(transcribe_audio, ASSEMBLYAI_API_KEY, audio_file): audio_file for audio_file in audio_files}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            audio_file = futures[future]\n",
        "            transcript = future.result()\n",
        "            if transcript:\n",
        "                print(f\"Transcription completed for {audio_file}: {transcript[:100]}...\")  # Display first 100 chars of the transcript\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czlojDLEWY8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV-uIAbMWVXS",
        "outputId": "fffd5da1-917c-40d9-f791-ac6f867df86f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n",
            "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNCMfgFJWan8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fac0690-11c0-45b3-9e09-bf65b3d46197",
        "id": "J0AegK-LWbDh"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=mdGpEqki8Lk', 'https://www.youtube.com/watch?v=AU_m12Nuk4k', 'https://www.youtube.com/watch?v=izZ0ZzsJ82A', 'https://www.youtube.com/watch?v=Og142I-11hw', 'https://www.youtube.com/watch?v=u7uOUHbhqXw', 'https://www.youtube.com/watch?v=O0P3FqKdUnY', 'https://www.youtube.com/watch?v=dJ3q7EEKI_8', 'https://www.youtube.com/watch?v=R6z_dkHAHh4', 'https://www.youtube.com/watch?v=3mNStBOkZ2U', 'https://www.youtube.com/watch?v=qw2-GVk8z4w', 'https://www.youtube.com/watch?v=LvxFWod6n98', 'https://www.youtube.com/watch?v=Orhca1vV8Uw', 'https://www.youtube.com/watch?v=HlQKQGvLeqo', 'https://www.youtube.com/watch?v=bUo7AAoHHfA', 'https://www.youtube.com/watch?v=AQFFMveRavQ', 'https://www.youtube.com/watch?v=4ZOMrfVKS9g', 'https://www.youtube.com/watch?v=zh2PTLPfmn8', 'https://www.youtube.com/watch?v=DhwBunH7pGc', 'https://www.youtube.com/watch?v=RbQAz9JPWKg', 'https://www.youtube.com/watch?v=y4HFT6VQodE', 'https://www.youtube.com/watch?v=4L8e73UvM0o', 'https://www.youtube.com/watch?v=NEYSq7IVBlY', 'https://www.youtube.com/watch?v=ur0wJJUWQtU', 'https://www.youtube.com/watch?v=fMKvX-I20T4', 'https://www.youtube.com/watch?v=9Y62poIdYzk', 'https://www.youtube.com/watch?v=92PsDZ_EVKw', 'https://www.youtube.com/watch?v=bOxY5GzN_Ao', 'https://www.youtube.com/watch?v=Ll0lRBeENIA', 'https://www.youtube.com/watch?v=Y0cvBWrHnUc', 'https://www.youtube.com/watch?v=2ZhZ5cjBSDI', 'https://www.youtube.com/watch?v=VVHXiEQdyJ4', 'https://www.youtube.com/watch?v=nT5Fre94kG4', 'https://www.youtube.com/watch?v=Qr3mUZsKNAk', 'https://www.youtube.com/watch?v=bM3rXtOT_8c', 'https://www.youtube.com/watch?v=IbHDY_fSkOU', 'https://www.youtube.com/watch?v=Ttf5Jo28iAs', 'https://www.youtube.com/watch?v=PcCBqfw3cPI', 'https://www.youtube.com/watch?v=oqDTNCGCvH0', 'https://www.youtube.com/watch?v=jTjrJ3s3Vwc', 'https://www.youtube.com/watch?v=bFZOIXCjpbs', 'https://www.youtube.com/watch?v=1fb6I5zm2h4', 'https://www.youtube.com/watch?v=iZYS1f9hoTY', 'https://www.youtube.com/watch?v=97lUdaryc78', 'https://www.youtube.com/watch?v=uaz7s7KKDNw', 'https://www.youtube.com/watch?v=iqxI9k6xm7o', 'https://www.youtube.com/watch?v=diqPJCZ-qIY', 'https://www.youtube.com/watch?v=oqnoMmw3yTY', 'https://www.youtube.com/watch?v=wNvdShXOUbY', 'https://www.youtube.com/watch?v=_Z-hZ_URBFE', 'https://www.youtube.com/watch?v=O-EoaHEui0k']\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=u7uOUHbhqXw\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Og142I-11hw\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=izZ0ZzsJ82A\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=AU_m12Nuk4k\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=O0P3FqKdUnY\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=dJ3q7EEKI_8\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=R6z_dkHAHh4\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=3mNStBOkZ2U\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=HlQKQGvLeqo\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=qw2-GVk8z4w\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Orhca1vV8Uw\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=LvxFWod6n98\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=bUo7AAoHHfA\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=AQFFMveRavQ\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=DhwBunH7pGc\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=4ZOMrfVKS9g\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=zh2PTLPfmn8\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=RbQAz9JPWKg\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=y4HFT6VQodE\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=NEYSq7IVBlY\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=9Y62poIdYzk\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=4L8e73UvM0o\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=ur0wJJUWQtU\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=fMKvX-I20T4\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=92PsDZ_EVKw\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Ll0lRBeENIA\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=bOxY5GzN_Ao\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Y0cvBWrHnUc\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=2ZhZ5cjBSDI\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=VVHXiEQdyJ4\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=nT5Fre94kG4\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Qr3mUZsKNAk\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=bM3rXtOT_8c\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=IbHDY_fSkOU\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Ttf5Jo28iAs\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=PcCBqfw3cPI\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=oqDTNCGCvH0\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=jTjrJ3s3Vwc\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=1fb6I5zm2h4\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=iZYS1f9hoTY\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=97lUdaryc78\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=bFZOIXCjpbs\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=uaz7s7KKDNw\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=diqPJCZ-qIY\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=iqxI9k6xm7o\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=_Z-hZ_URBFE\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=wNvdShXOUbY\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=oqnoMmw3yTY\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=O-EoaHEui0k\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=u7uOUHbhqXw\n",
            "[youtube] mdGpEqki8Lk: Downloading webpage\n",
            "[youtube] u7uOUHbhqXw: Downloading webpage\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=dJ3q7EEKI_8\n",
            "[youtube] dJ3q7EEKI_8: Downloading webpage\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=DhwBunH7pGc\n",
            "[youtube] DhwBunH7pGc: Downloading webpage\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=_Z-hZ_URBFE\n",
            "[youtube] _Z-hZ_URBFE: Downloading webpage\n",
            "[youtube] mdGpEqki8Lk: Downloading ios player API JSON\n",
            "[youtube] mdGpEqki8Lk: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=mdGpEqki8Lk: ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n",
            "[youtube] u7uOUHbhqXw: Downloading ios player API JSON\n",
            "[youtube] u7uOUHbhqXw: Downloading mweb player API JSON\n",
            "[youtube] dJ3q7EEKI_8: Downloading ios player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] u7uOUHbhqXw: Video unavailable. This video contains content from WMG, who has blocked it in your country on copyright grounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=u7uOUHbhqXw: ERROR: [youtube] u7uOUHbhqXw: Video unavailable. This video contains content from WMG, who has blocked it in your country on copyright grounds\n",
            "[youtube] _Z-hZ_URBFE: Downloading ios player API JSON\n",
            "[youtube] DhwBunH7pGc: Downloading ios player API JSON\n",
            "[youtube] _Z-hZ_URBFE: Downloading mweb player API JSON\n",
            "[youtube] dJ3q7EEKI_8: Downloading mweb player API JSON\n",
            "[youtube] DhwBunH7pGc: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] _Z-hZ_URBFE: Video unavailable. This video contains content from NBC Universal, who has blocked it in your country on copyright grounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=_Z-hZ_URBFE: ERROR: [youtube] _Z-hZ_URBFE: Video unavailable. This video contains content from NBC Universal, who has blocked it in your country on copyright grounds\n",
            "[youtube] dJ3q7EEKI_8: Downloading player 5b77d519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] DhwBunH7pGc: Video unavailable. This video contains content from NBC Universal, who has blocked it in your country on copyright grounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=DhwBunH7pGc: ERROR: [youtube] DhwBunH7pGc: Video unavailable. This video contains content from NBC Universal, who has blocked it in your country on copyright grounds\n",
            "[youtube] dJ3q7EEKI_8: Downloading m3u8 information\n",
            "[info] dJ3q7EEKI_8: Downloading 1 format(s): 251\n",
            "[download] Destination: downloads/Jerome Powell LIVE @ 1_45PM EST - Stock Market LIVE, Live Trading, Stocks To Buy NOW.webm\n",
            "[download] 100% of  365.82MiB in 00:00:20 at 17.93MiB/s  \n",
            "[ExtractAudio] Destination: downloads/Jerome Powell LIVE @ 1_45PM EST - Stock Market LIVE, Live Trading, Stocks To Buy NOW.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: Postprocessing: audio conversion failed: Exiting normally, received signal 2.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1043c8d3ccf5>\u001b[0m in \u001b[0;36m<cell line: 157>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-1043c8d3ccf5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Step 3: Download audio files for failed videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed_videos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mdownload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# Step 4: Transcribe downloaded audio using AssemblyAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1043c8d3ccf5>\u001b[0m in \u001b[0;36mdownload_audio\u001b[0;34m(video_links)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt_dlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYoutubeDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydl_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_links\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    243\u001b[0m                             len(pending), total_futures))\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import concurrent.futures\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"  # Replace with your valid YouTube Data API v3 key\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"  # Replace with your AssemblyAI API key\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while True:\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token or len(video_links) >= 2:  # Stop after collecting 2 videos\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    failed_videos = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize transcript fetching\n",
        "        futures = {executor.submit(YouTubeTranscriptApi.get_transcript, link.split(\"v=\")[1]): link for link in video_links}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            link = futures[future]\n",
        "            try:\n",
        "                future.result()  # Will raise an exception if transcript fetch fails\n",
        "                print(f\"Transcript fetched successfully for video: {link}\")\n",
        "            except (TranscriptsDisabled, NoTranscriptFound):\n",
        "                print(f\"Transcript not available for video: {link}\")\n",
        "                failed_videos.append(link)\n",
        "\n",
        "    return failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize audio downloading\n",
        "        futures = {executor.submit(yt_dlp.YoutubeDL(ydl_opts).download, [link]): link for link in video_links}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            link = futures[future]\n",
        "            try:\n",
        "                future.result()  # Will raise an exception if download fails\n",
        "                print(f\"Audio downloaded successfully for video: {link}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Main function to stop after processing two videos\n",
        "def main():\n",
        "    channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # Replace with the actual channel ID\n",
        "\n",
        "    # Step 1: Get the first two video links from the channel\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "\n",
        "    # If less than two videos, stop the process\n",
        "    if len(video_links) < 2:\n",
        "        print(\"Not enough videos found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    failed_videos = fetch_transcripts(video_links)\n",
        "\n",
        "    # Step 3: Download audio files for failed videos\n",
        "    if failed_videos:\n",
        "        download_audio(failed_videos)\n",
        "\n",
        "    # Step 4: Transcribe downloaded audio using AssemblyAI\n",
        "    audio_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Parallelize audio transcription\n",
        "        futures = {executor.submit(transcribe_audio, ASSEMBLYAI_API_KEY, audio_file): audio_file for audio_file in audio_files}\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            audio_file = futures[future]\n",
        "            transcript = future.result()\n",
        "            if transcript:\n",
        "                print(f\"Transcription completed for {audio_file}: {transcript[:100]}...\")  # Display first 100 chars of the transcript\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oDh4WKZiW4Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"  # Replace with your valid YouTube Data API v3 key\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"  # Replace with your AssemblyAI API key\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "# Fetch 2 videos (one with transcript and one without)\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while len(video_links) < 2:  # Stop after 2 videos\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "                if len(video_links) >= 2:\n",
        "                    break\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([link])\n",
        "            print(f\"Audio downloaded successfully for video: {link}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # Replace with the actual channel ID\n",
        "\n",
        "    # Step 1: Get 2 video links from the channel\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    if len(video_links) < 2:\n",
        "        print(\"Not enough videos found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    failed_videos = fetch_transcripts(video_links)\n",
        "\n",
        "    # Step 3: Download audio files for failed videos\n",
        "    if failed_videos:\n",
        "        download_audio(failed_videos)\n",
        "\n",
        "    # Step 4: Transcribe downloaded audio using AssemblyAI\n",
        "    audio_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "    for audio_file in audio_files:\n",
        "        transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_file)\n",
        "        if transcript:\n",
        "            print(f\"Transcription completed for {audio_file}: {transcript}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "119xvpQdW4Vg",
        "outputId": "a3044788-9d0a-4271-96d6-f9b54d68d86a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=mdGpEqki8Lk', 'https://www.youtube.com/watch?v=AU_m12Nuk4k']\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=AU_m12Nuk4k\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "[youtube] mdGpEqki8Lk: Downloading webpage\n",
            "[youtube] mdGpEqki8Lk: Downloading ios player API JSON\n",
            "[youtube] mdGpEqki8Lk: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=mdGpEqki8Lk: ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "YOUTUBE_API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"\n",
        "channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # The channel ID you provided\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "# Fetch 2 videos (one with transcript and one without)\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while len(video_links) < 2:  # Stop after 2 videos\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_status = youtube.videos().list(\n",
        "                    part=\"snippet, liveStreamingDetails\",\n",
        "                    id=video_id\n",
        "                ).execute()\n",
        "\n",
        "                # Check if the video is scheduled or live (skip if scheduled or live)\n",
        "                live_status = video_status[\"items\"][0].get(\"liveStreamingDetails\", {}).get(\"liveStatus\", None)\n",
        "                if live_status in [\"upcoming\", \"live\"]:\n",
        "                    continue\n",
        "\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "                if len(video_links) >= 2:\n",
        "                    break\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([link])\n",
        "            print(f\"Audio downloaded successfully for video: {link}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Step 5: Save videos in a zip file\n",
        "def save_videos_to_zip(video_files, zip_filename):\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for video_file in video_files:\n",
        "            zipf.write(video_file, os.path.basename(video_file))\n",
        "    print(f\"Videos saved to {zip_filename}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Step 1: Get 2 video links from the channel\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    if len(video_links) < 2:\n",
        "        print(\"Not enough videos found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    failed_videos = fetch_transcripts(video_links)\n",
        "\n",
        "    # Step 3: Download audio files for failed videos\n",
        "    if failed_videos:\n",
        "        download_audio(failed_videos)\n",
        "\n",
        "    # Step 4: Transcribe downloaded audio using AssemblyAI\n",
        "    audio_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "    for audio_file in audio_files:\n",
        "        transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_file)\n",
        "        if transcript:\n",
        "            print(f\"Transcription completed for {audio_file}: {transcript}\")\n",
        "\n",
        "    # Step 5: Save the processed videos to a zip file\n",
        "    video_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "    if video_files:\n",
        "        save_videos_to_zip(video_files, \"test.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHHruPn6YO3O",
        "outputId": "521db6c4-51db-47d4-f520-d428b7eea50e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=mdGpEqki8Lk', 'https://www.youtube.com/watch?v=AU_m12Nuk4k']\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=AU_m12Nuk4k\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "[youtube] mdGpEqki8Lk: Downloading webpage\n",
            "[youtube] mdGpEqki8Lk: Downloading ios player API JSON\n",
            "[youtube] mdGpEqki8Lk: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=mdGpEqki8Lk: ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n",
            "Videos saved to test.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "YOUTUBE_API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"\n",
        "channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # The channel ID you provided\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "# Fetch 2 videos (one with transcript and one without)\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while len(video_links) < 2:  # Stop after 2 videos\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_status = youtube.videos().list(\n",
        "                    part=\"snippet, liveStreamingDetails\",\n",
        "                    id=video_id\n",
        "                ).execute()\n",
        "\n",
        "                # Check if the video is scheduled or live (skip if scheduled or live)\n",
        "                live_status = video_status[\"items\"][0].get(\"liveStreamingDetails\", {}).get(\"liveStatus\", None)\n",
        "                if live_status in [\"upcoming\", \"live\"]:\n",
        "                    print(f\"Skipping video {video_id} as it is scheduled or live.\")\n",
        "                    continue\n",
        "\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "                if len(video_links) >= 2:\n",
        "                    break\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([link])\n",
        "            print(f\"Audio downloaded successfully for video: {link}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Step 5: Save videos in a zip file\n",
        "def save_videos_to_zip(video_files, zip_filename):\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for video_file in video_files:\n",
        "            zipf.write(video_file, os.path.basename(video_file))\n",
        "    print(f\"Videos saved to {zip_filename}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Step 1: Get 2 video links from the channel\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    if len(video_links) < 2:\n",
        "        print(\"Not enough videos found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    failed_videos = fetch_transcripts(video_links)\n",
        "\n",
        "    # Step 3: Download audio files for failed videos\n",
        "    if failed_videos:\n",
        "        download_audio(failed_videos)\n",
        "\n",
        "    # Step 4: Transcribe downloaded audio using AssemblyAI\n",
        "    audio_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "    for audio_file in audio_files:\n",
        "        transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_file)\n",
        "        if transcript:\n",
        "            print(f\"Transcription completed for {audio_file}: {transcript}\")\n",
        "\n",
        "    # Step 5: Save the processed videos to a zip file\n",
        "    video_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "    if video_files:\n",
        "        save_videos_to_zip(video_files, \"test.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd_2A1NRYxTC",
        "outputId": "99836ce7-1ac0-4b24-db64-9d8cec60df9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=mdGpEqki8Lk', 'https://www.youtube.com/watch?v=AU_m12Nuk4k']\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=AU_m12Nuk4k\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "[youtube] mdGpEqki8Lk: Downloading webpage\n",
            "[youtube] mdGpEqki8Lk: Downloading ios player API JSON\n",
            "[youtube] mdGpEqki8Lk: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=mdGpEqki8Lk: ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n",
            "Transcription completed for downloads/Jerome Powell LIVE @ 1_45PM EST - Stock Market LIVE, Live Trading, Stocks To Buy NOW.mp3: I think it's alive. Good morning, ladies and gentlemen. I hope you're having a wonderful day. It is December 4, 2024, and we have a wild day ahead of us. Hopefully it does not get filled with black swans like yesterday in Korea. That was absolutely wild like yesterday. To start off this morning, people are feeling good. Everybody's feeling generally okay. You have not had any extra spillover from last night. You had the martial law rescinded. And then you're going to have another event here, I think around 2:40pm our time. So we'll see where it takes us there. But other than that, you had data here in the morning. Everything was fine. And then on top of it, now we have Jerome Powell and the ISM services. So we'll see where things play out from here. And then, honestly, even right now, this is actually breaking news as I'm going live. The United Health CEO was fatally shot in Manhattan. Yeah, no, that's actually coming. It's actually kind of wild. And then you have Baidu, and then Apple hit snags adapting Baidu's AI model for China users. So I don't. I don't know why Baidu is going down on them working with Apple, but either way, man. Good morning. But if you are new and you have no idea what we are doing here, you are about to watch seven hours of the stock market. We have a live momentum indicator right here. You'll see the highs and lows. So even before I read you the Baidu news, you could take a look here. There you go. It's already moving around, so you can see what's up with that. You have the S and P in the top left, bonds in the bottom left. You have the beautiful Chad, baby. Oh, my goodness. And that's the best part. The only bad side is that if you are new, you will not be able to chat for about 24 hours. Why? Because I want you to learn how to make an investment in yourself. And by that means, holding and waiting and being patient, both in the chat and in your portfolio. And this is one big thing that we do here. Yeah, we could get you the news, we could get you plays and a lot of other things. But at the end of the day, you have to make sure that you own stocks from the moment you know about the stock market and save 10%, and your life will change and you will gain wealth because capital outpaces labor, baby. So we've posted all of these on this channel, even on my Twitter there. But we built it from the ground up. Man, I hope you get one too. But. Chattedonia. Good morning, baby. What's going on? Honestly, I thought today wasn't going to be crazy. And then literally the CEO of UNH just got shot and killed on the street of New York, man. What the hell is happening right now? Good morning. What up, pnc Mark Awaz Dos Nachos, Najee Wolf. Good morning, baby. What up? Tyree Jackson's Regal Lake R.J. good morning, baby. Uncle Terry, Lucky Soulja. What up baby? How we live in Andros Owen Tim Whitman, Monica Ashley, Kurt McGuire winning loser, baby. Jerry, Jerry, Jerry, Jerry, will ya? Good morning. Oh, Gus. Gonzo in the house. Jamar in the house. Me not you. Ready to go? What up, baby? What up, Jeff Kentucky what up, Tyler? What up, Gunner? Rob Smart Bride Shane, Agent of Chaos Paddleboard. What's up baby? How we doing? Lego? What's going on? Takutsu that Takatsu. Takat. You just broke me, bro. I don't know what am I saying right now. What up, Suraj? What up, Emilio Turbo Na Brown Tom Crows again and don't get smashed. What about the twitch, baby? We got Lucky J Swinging Bear, T Toksy F, the Feds, Blizzy. That's his name. That's his name. Lucky J, Slizzin, Blowing Dough, Roach, Vince, Mr. Glocks, triple three, hit and run, Hippo Epic, Eric Robo Hand Tech and Blazing Bob, baby. Good morning. Wow. So Chattedonia, I hope you guys know you have Powell today, right? So it'll be a fun day. I hope you're locked and loaded. But now here, in the meantime, it is Josh AI with the plays. Oh, what up, Mr. James Cash. Good morning. Tech stocks lead gains in US futures before Powell and tech stocks led an advance in US Equity futures. And traders looked ahead to remarks from Federal Reserve Chair Jerome Powell for clues on the outlook for interest rates. Nasdaq 100 index contracts climbed 0.7% comma buoyed by positive earnings news in the sector. S&P 500 contracts edged higher after the benchmark eked out its 55th record high of the year on Tuesday. The dollar strengthened in 10 year treasury yields climbed. French markets were relatively stable before Wednesday's no confidence vote that threatens to topple the government. South Korea's one rebounded after President Yoon Suk Yeol rescinded his shock declaration of martial law. Powell's speech and U.S. data on services and manufacturing will capture attention later in the buildup to Friday's crucial update on the American labor market. Fed bank of San Francisco President Mary Daly said a December rate reduction isn't certain but remains on the table. The Fed has been quite clear up until now in their signaling, so if they were going to pause, Powell might give some signals because they won't want to surprise the market, said Guy Miller, chief strategist at Zurich Insurance. But I do think they will cut by 25 basis points this month. The surge in U.S. stocks that has driven the S P 500 index 27% higher this year shows few signs of fading, according to strategists at Barclays plc. Powered by the election of Donald Trump and a positive economic backdrop, it is hard to see an end to US Exceptionalism anytime soon, which we think remains the playbook into 2025, the team, lead by Emmanuel Cao, wrote in a research note. In France, the CAC 40 stocks index rose marginally, outperforming Europe's regional Stoxx 600 gauge. While the yield premium on French bonds over their German equivalents was steady, the euro weakened slightly. The stability in assets before Wednesday's vote came as no surprise to Nanette Heckler, Federb Emea, chief investment officer at Lombard oda. This is not a crisis of the style we had during 2012 and 2013 with the European debt crisis, she said. France has a current account deficit that is tiny when you think about it, which means it has the ability to recycle and fund the government debt internally. That is its strength on which markets can take solace and build. On Korea shock and investors are assessing what's next for South Korea after the opposition Democratic Party said it will pursue charges of treason and impeachment against Yoon for declaring martial law illegally. The bank of Korea said it will increase short term liquidity and take active steps in currency markets as needed to ensure stability. And there's certainly some lingering uncertainty with a quick response from Korean authorities means that impact on the region could remain limited, said Charu Chanana, chief investment strategist at Saxo Markets. Oil steadied after the biggest advance in more than two weeks Gold stabilized after rising on Tuesday as the political turmoil in South Korea and France buoyed demand for haven assets. Corporate HIGHLIGHTS Eli Lilly & Co. Said its weight loss drug Zepbound outperformed rival Novo Nordisk as Wegovy in the first head to head trial of the two blockbusters. General Motors Co. Will incur more than $5 billion in charges and write downs tied to its troubled operations in China as the automaker tries to salvage its once profitable business in the world's largest car market. Dollar Tree Inc. Shares soared after sales improved in the third quarter, a sign the discounter is making headway in fending off competition and drawing in more shoppers. Royal bank of Canada beat estimates after setting aside less money than expected for potentially bad loans. Salesforce Inc. Shares were on track for a record high in early trading after reporting quarterly revenue that topped analysts estimates, boosted by investor hopes that the company's much hyped strategy for artificial intelligence products will lift financial results. Mastercard Inc. Has agreed in principle to pay around 200 million pounds $254 million to settle a UK class action lawsuit, according to a person familiar with the matter. French instability President Emmanuel Macron called on French lawmakers to set aside their personal ambition and reject a vote that would topple the government and throw the country into political turmoil. President Emmanuel Macron called on French lawmakers to set aside their personal ambition and reject a vote that would topple the government and throw the country into political turmoil. Debt dangers in the global economy faces proliferating risks ranging from trade tensions to wars and debt troubles that could threaten its remarkable resilience of past years, the OECD said. Just weeks away from Donald Trump assuming the US Presidency in January, the Paris based Club of Rich Economies Economies applauded the world's recent experience of stable growth in ebbing inflation while warning that notable dangers are lurking on the horizon. Robust overall performance masks significant differences across regions and countries and is surrounded by important downside risks and uncertainties, oecd Chief economist Alvaro Pereira wrote in the report that sees the world economy expanding 3.3% in each the next two year. There are increasing risks related to rising trade tensions and protectionism, a possible escalation of geopolitical conflicts and challenging fiscal policies in some countries. London Shrinking market Bankers love it when there's a flood of mergers and acquisitions for stock exchanges, it's not always such good news. Look at London Takeovers of UK Listed companies are shrinking the country's stock market at the fastest pace in more than a decade. About 45 companies have delisted from the London Stock Exchange this year due to takeovers, up 10% from the tally for all of last year, according to data. That's the highest number of firms to leave the market since 2010 and comes as the volume of deals targeting UK companies jumps 81% this year to more than $160 billion. Top overnight news South Korea's opposition submitted an impeachment motion against President Yoon Suk Yeol after he briefly imposed martial law, sparking calls for his resignation local stocks closed lower while the one erased most of its overnight loss. BBG South Korea's central bank said it would boost short term liquidity and take steps to stabilize the currency as needed, but governor Ri Chang Yong said it is unlikely the central bank will cut interest rates. BBG China Auto sales surged in November, likely on the back of price cuts and government stimulus initiatives. Retail vehicle sales grew to 2.4 million in November, up 18% compared with last year. BBG French Stocks gained and bond spreads narrowed as President Emmanuel Macron urged lawmakers to reject a no confidence vote that would topple the government. He said he won't resign before his term ends. Voting is due to start after 4pm local time. BBG the BOE has scoped to reduce rates at least four times in 2025 if its UK economy outlook bears out, Governor Andrew Bailey said in the FT reported. Inflation has fallen faster than expected a year ago, he said FT final GOP majority in the house will be 220, 215 after the last race in California was officially called, but the split will be 217215 in the opening months of the Trump administration as Trump is taking two House Republicans into his cabinet and Gates resign. NYT Robert Lighthizer the former US Trade chief is unlikely to rejoin the Trump administration in an official capacity. Lighthizer could still be selected by Trump for a formal advisory role in the administration, though his hopes of landing a high level cabinet job have slipped away. WWT President Elect Donald Trump is considering Florida Governor Ron DeSantis as a possible replacement for Pete Hegseth, his pick to run the Pentagon as Secretary of Defense. WSJ Advisors to Donald Trump publicly and privately are floating proposals to end the Ukraine war that would cede large parts of the country to Russia and taking NATO membership for Ukraine off the table. Reuters US Speaker Mike Johnson anticipates the stopgap funding bill will expire in late March 2025. A final decision is expected in the coming days, according to Punchbowl News. BBG yeah, so why and then again it wasn't the CEO of unh, it was somebody who is a part of United Health Group. So yeah, very weird so far. I thought the homeboy just got shot in the street. It was at investor day so that I'm the way I don't know about the full story right now so I'm gonna get something wrong about it, but it sounds like somebody pulled up to investor day pretty mad and then you know popped off there. That was pretty wild. Or he was shot at his hotel. Well, they're saying it was at the investor day because it just kicked off and then they just shut it down right now. And then again there's a difference between United Health Care and United Health Group, but either way, I don't know. Are we starting off every single one of these mornings with crazy headlines? It seems like, my goodness, you hear Josh AI trip out. Yeah, it's pretty wild. This game is getting kind of hot in here, bro. So we still got more news. S and P futures there by point three Wednesday morning trading comes after US equities put in another mixed performance on Tuesday. However, S and P finished up for the 10th time in the last 11 sessions and the Nasdaq closed at a new all time high as tech outperformance continued. Treasuries weaker across the curve, dollar up by 0.2 with the yen and Aussie weakness softer, GDP in focus Gold flat, bitcoin up by 0.2 and WTI is up by 0.4 November NFP continues to loom as the next big directional driver for the market amid the waiting game. Recent focus has been on tech outperformance following the rotational drag in November, while the latest batch of earnings also keeps the focus on AI Dovish leaning Fed speak has also been in the headlines this week, though officials are not front running some key macro data into 18 December. No meaningful spillover from overseas political complications, a dynamic that may fit with the momentum behind the broader US Exceptionalist trade. November ADP payrolls came in just below consensus, with October revised down by nearly 50,000 jobs, release noted. Overall job growth remained healthy, though industries mixed manufacturing shed jobs. Added pay gains accelerated in November. ISM Services, factory orders and beige book on the calendar today. ISM expected to tick down to55.5 in November from 56 in October, but continue to highlight the tailwind from service side of the economy. Factory orders expected to increase by 0.4 after a 0.5 contraction in September, said St. Louis Fed Muslim said pause possible at upcoming meeting warned cutting too much higher risk than easing too little while Chair Powell is at 1:45pm today. Recent Fed speak has leaned dovish, though most officials have refrained from explicitly committing to a December rate cut. CRM up on better quarter three revenue and crpo, while takeaways focused on agent force and data cloud. Marvel beat and guided above with custom AI silicon programs. The key driver Pure storage up big with focus on design at leading hyperscaler Octa another post turning standout with takeaways product on new product or positive on new product Sales base down revenue deceleration and slowing customer ads consumer space and focus dollar tree beating on comps margin and EPS However Campbell sales light with both M and B and snacks missing on organic growth Hormel Q4 results in 4 year 25 guide light footlocker under pressure on quarter 3 miss and reduced full year 24 outlook chewy beat and raised but EBITDA margin issue would drag on The Stock Healthcare UNH 2025 Revenue Guidance Ahead while EPS captured street at the high end United Healthcare segment CEO also killed in shooting GM announced 5 billion in China write off charges ODFL Mid Q update showed some sequential improvement CRGY down on acquisition and secondary and I think that's it. Oh my goodness. Yeah I think that's all of your headlines. I don't have any more is like a difference United Health Group it's either a new it's a brand new company or it's a segment it's the United Healthcare segment CEO so just somebody as part of it but still very very weird headline but my goodness my friends good morning and now we have plays. We're definitely ahead of schedule right now so let's see what we working with baby. Pure storage is up by 22.2off earnings Octa is up by 13.1off of earnings Marvel 12.9off of earnings CRM up 12 off earnings Roku up 5.3Needham says likely to be bought out in NTM Dollar Tree up 4.9off earnings Hood is up by 3.1They gave a market update Coharis is up by 2.8Jeffries initiates Buy EW up 2.7outlines growth strategy TRMB is up by 2.4JP Morgan upgrade Chipotle up 2.2True raises estimate in price targets GEV up 2.2Wolf Research initiates outperform NC is up by 2 FDA grants orphan drug designation to Manjuvi for splenic and extranodal MZL ANET is up by 1.9 CEG up 1.5 Eli Lilly up 1 surmount study Zipbound vs. Wegovy Roblox up by 1 MCHP is up 0.9 reportedly pausing application for US semiconductor subsidies NXC is up by 5.8 first Geranium sales contract for £5 million with major US utilities JetBlue is up 5 guidance PBI up 4.9 Hastia Capital Management discloses additional info regarding 10b5 plan PL is up by 4.1Oclo is up 3.5ardx up 3 Novak's up to 1 to sell Czech Republic manufacturing facility to Novo for 200 million. HRTX is up by 70. Court ruling CCRN is up by 61 to be acquired by AYA Healthcare. SLND is up by 11, 8, 60 million. Wastewater treatment award UM Y91 follow through on China export ban. Avir is up 4, 9. Phase two study of BEMNI, Fossebuver and Roosevelt meets primary endpoint. ARQQ is up by 3. 7. HMX up by 3, 5, 20 million. Share buyback program. Bitcoin stocks trading higher. Campbell's trading lower by 3. 4 earnings and CEO Transition Chewy down 3 earnings. Hormel down 2, 8 off earnings. UNH down by 0.2. Guidance ahead of investor conference. ZJK down 17. 9. Stock rose 100% yesterday on Nvidia Collaboration Footlocker down 17 off earnings. Nike down in sympathy Lunar down 16, 3, 65 million. Common stock offering 10 million. Concurrent private placement base is down 9. 2 off earnings. GXO down 8, 5. Reportedly to turn down acquisition offers and remain independent. FSM down by 5, 6. THO down 5. 1 Earnings CRGY down 4. 2. Acquisition RVMD down 2, 6. Prices 750 million offering IREN down 1 4, 300 million. Convertible offering RLMD down 73. 4. DMC assessment indicates phase 3 Reliance trial is futile at interim analysis Analysis oris is down by 39. Stock was up 82 yesterday. PSQH down 32. Stock was up 270 yesterday on Trump Jr board appointment and shim down six six and galt down by four eight. Yallah. My goodness. So good morning Chattedonia. I hope you guys are living blessed. I hope you are feeling good but we're mad early, bro. We are mad. Oh, who was that? And I posted these on Twitter. If you guys go real cult news, you'll find the pre market movers. I'm not live on Twitter yet because they're going to kick me off by the time Powell comes on, so might as well get on there later. But who was it? I think it was NNE. One of them was actually that was your first nuclear deal. They got the £5 million. Oh, my thing is not loading. Well, we'll go. Yeah, yeah, here it is. Which one was it? Was it nne? N X E. Yes, thank you, Tyler. It is right there as well. So great. Nxe. That's the one. That one's going to be interesting because again yesterday they. They announced that stuff. What was it? There was a bunch of stuff at Amazon with like nuclear power and all of that. So we will see where it takes us. But ladies and gentlemen, boys and girls, you're here right now. Let me see actually. Otherwise if there's no, there's no commercial break, I'm gonna go pee. Otherwise, let's just get right into the plays, baby. I don't know. It's kind of already feeling like it's going to be a crazy day. I'm not really expecting much out of pow pow rate cuts and I wonder just how much optimism that we are Follow me on Instagram of an easing at the trading fraternity counter. That way I will be RB from Williams. There's Twitter and I love you. Good morning. I have to pin this as well. All right, both, all three of them are somewhat hinting at potential cut for this December meeting. But I think the market's already sort of pricing in maybe in every other going forward and looking at an incremental 2 or 3 for the rest of next year which I think is probably right now. I think from this perspective though, rates are still restrictive. There's room for them to ease at the margin. Maybe don't have to go five or six times but we're still on a restrictive level and I think that is the underlying narrative here. But how much further can we go? I mean the market's pricing in I think a 4% terminal rate and the dot plot, at least the last one we got is for 3%. So that's, that's a pretty big dispersion. Yeah. And I wouldn't be shocked when we get that new ACP out. You're going to see some of those dots drift higher. So you know, I think the market's probably right smack dab where they should be right now in terms of expecting rate cuts going forward and then it's going to go back to data dependency if things start to slow. I think that Powell put kicks back in and you're going to see the potential for maybe more pricing of rate cuts going forward. But if the data remains firm, we probably still stay on this holding pattern here. What does it mean for the mix of stocks and bonds in your portfolio? Because it's interesting the 10 year we've been watching it so closely. Yesterday we watched Katie point out less than 420 on the 10 year. You're now back to 426. The volatility is incredible. And if you believe you're then do you buy 26 basis points, DP valuations or some period the bond market Thanksgiving probably going to be earning your maybe you get marginal oh, dude. Oh, dude. So, Chattedonia, what's up, baby? You here right now? He living blessed, man. I hope y'all living good. You're here right now. Let me spam the chat with the Twitter real quick. But now after I spam, it's your turn, baby. Let's go. You got to hear about the basis points you've already heard. Dude, we waking up to wild news every day. So you're here right now, Chattedonia. Tell me, what is your first play of the day, baby? What do you got for me? Let's go. Hold on. I can't hit the desk. I'm putting my desk down. Calls on Amazon, ASML. Good morning, baby. ARM Navidea calls on the chat all day. FedEx calls Broadcom, Zscaler, IWM calls SMCI puts intel called Nvidia call. Q. Q. Q. Intel call SMPs selling Nvidia 140 Hodl. Broadcom calls. SMCI calls Amazon bidding make CRM free. Nvidia zero day spy calls. GME chewy calls holding intel long Jesus calls Nvidia call Twilio, Cost, Sit and Fish CEO of UNH. CRM377 for December 6th. We're supposed to play CRM again, baby. Adding Intel, Estee Lauder, TSM spy calls buying NASDAQ 100 Alab long Nvidia. January 150 TTC Marvel calls. Two coffees and 30 push ups. Rare Earth Materials FL puts Nvidia Intel Spy calls in the final plays. Intel calls selling Nvidia calls Hood play, Sofi, Costco. And tantalizing puts. I'm glad that word trips you out. Like, it trips me out. You know, I. I'm. I swear, we gonna hear tantalizing so much in 2025. They can't. They can't help themselves. You know? It's a new buzzword, bro. It's tantalize. I hate it. I hate it, man. Oh, my gosh. Well, tantalizing puts way to end it, baby. So, Chad, we got a little bit of time, but now something's more important than all of it. More important than the market, than a coup. I don't know, man. Everything, bro. We do this every single day. And I'm honored. And even more so, man. It's one thing I hold truly and deeply in my heart. But I'm honored to serve y'all the way y'all have served above and beyond. And what I'm talking about is the veterans of the United States of America. So before we start our day, before we do anything it is only right that we shout out the best and greatest of all of us, those who have made the ultimate sacrifice and given a sacrifice that we take for granted so easily. So the least we could do is offer it. I hope I get you all the long term. Let's get you a crib as well, too. But if you have the opportunity to show this love and bring it out into the real world, I strongly encourage it. Because without the veterans, man, I don't even know, bro. And they've given up so much, and it's something that we should honor. So, veterans, the families, thank you for your sacrifice and everything you have given to this country. And big shout out to anybody else out there giving back to their local communities. All the doctors, nurses, teachers, firefighters, police officers, the janitors, the coaches, the garbage men, anybody making their community run, God bless you and thank you, baby. But ladies and gentlemen, please rise. Place your right hand over your heart. Say it with me. I pledge allegiance to the flag of the United States of America and to the republic for which it stands, one nation under God, indivisible, with liberty and justice for all. Baby. Senator Church. Oh, it's game time, baby. Ho. Chattedonia chadonia. How you feel, baby? How do you feel? Are we feeling good? Are we feeling good? So I got a couple plays, man. I got a couple of plays. Let's see. All right. Oh, yeah. Wait, Am I on the place? There it is. I was like, why can't I find my place, huh? That scared me for a second. So I'm gonna watch a couple again. We only made one play yesterday. We'll see what anything in currency land does, AKA crypto as well. But I'm gonna be watching CRM and octa. I don't know if the octas again, they look good. I don't know if they'll hit Foot Locker and Nike. That'll be another one. Again, Marvel, like I told you, that thing has power. So if it finally wants to break out, that will be awesome. And then watching the short end of the curve, keep eye on Robin Hood and intel. And then NXE. The last 48 hours, there has been a lot of nuclear headlines. So we'll see how that plays out. And fed Barkin right now is talking the bar to raising prices to raising prices in lower than it was before. Pandemic. That makes no sense. Doesn't know where balance sheet will need to stop contracting says Muslim. So you have Fed barking and Muslim speaking right now. And then we got 47 seconds till the bell, baby. So like that video. Show some love. You need anything, you let me know you got your news wire and then you follow me on Twitter. Other than that. Let's go. And good luck. Good luck again. Bonds already starting down, so today was not their day for the rally and then we'll see where CRM and everybody else is at, baby. So good. Good luck. Yeah, ism. The services is going to be big. That was. We already had a reaction on manufacturing so definitely keep your eyes out for that one and then good luck. All right, 15 seconds. You like China for the long term? Yeah. I mean they're up from where I bought them. So you have to factor that into the other long term stuff that we've talked about. And there was a little long term lesson on the watch list. Three, two, one. Round. One fight. Okay, where are we at? City. Oh, those cities are just tweaking. All right, I'm seeing. I don't see this. I don't know if the CRMs have opened yet. CRMs, they look like they're down and then Octa. Octa is down as well too. They hate us. So tada. Again. They didn't move more than two standard deviations sadly. So I think. Yeah, well actually CRM was two standards at pre market. So literally it's already down $10 from an hour ago. And then same thing with Octa. So yeah, they all just fell back to what was priced in unfortunately. So you either wait or you could pull out for break even. They're actually, they're actually dropping right now. So we will see. CRM's now trying to move. Hold on. Yeah. Okay, now the CRMs are up. I don't know what the hell is happening. I think it just a bit and ask. That thing is tweaking so watch out for that. Where's the other one? NXC CMG. 2% price boost. Hmm. UPS clapped. Let's see. Watch it. Octa is about to sell off 15% right there literally from the pre market high. Disney going up. Who is the other one? Foot Locker. Don't forget about that, Beto. Yeah. Foot lockers already down 18. That one won't stop. Surprisingly, Chipotle just went up 3%. I don't know if it's off of that headline or not. So watch out for the Estee Lauder, bro. I wish we held that one play, man. Holy crap. That thing is crazy. El Big drop. I only see a big rise. Oh, you said. Oh a big pop. I thought you said big drop. It's like I don't know about that. And then Roku again, they were saying, some analysts said that they're gonna get bought out but there's no like real headline or news around it. So we will see. Yeah, the CRMs are like holding. It's just a wild spread. If CRM bounces those will come back up. But if not, you're gonna get Clapper running. Roku going up. DDD on the high. Where was it? AS nxe. Yeah. Was this the one that got the deal? Foot Locker. For the long term I would just rather buy Nike to be honest. But I mean Foot Lockers is pretty volatile. I mean it's that thing. I feel like the last three years it's done a lot of back and forth. I'm not like opposed to it but like I'm saying, I mean I have Nike already and I'd probably end up going with that one. And then Bond still dropping here. I haven't looked at the dollar today again, Spy. Actually this is almost everything today. Dow is doing as good as the nasdaq, which is ironic. And then Spy and Russell are pretty much matched up. So this is yesterday. Last two days were outperformance to start off now. I mean I don't know what you would call this. It just, it looks like everything everywhere all at once. Pinduoduo on the high coinbase starting to work its way up. You guys are just calling Albedo. Where's Young arc? ARC is starting to go up. Let's see. Regional banks. Honestly all the trades are going up there and again I think the dollar should be up there. It is. Polis Central banks leave rates unchanged. ELF going nuts. Yeah, up 4.4. That's actually big square, 52 week high. Oh, IBB. You're right, that is one of the long duration plays. But that thing hasn't really. It dropped down a lot and then moved up. It's still like kind of in the middle. If there's a cheaper biotech play, that one could actually be decent. Yeah, Snow's been going nuts the last couple of days. Oh, Nibis Citron was pumping that one. They're saying, remember this was the Russia stock, this was Yandex. And then they spin it off and then they sold some of it to Europe. We've talked about this many times but people are getting hyped on it and apparently it does have an AI link. I do remember talking about that. Okay, nxc. Was this thing higher in the morning? This place scares me but I kind of like it for nuclear. It's up a lot already but. And I don't know how much it's going to move but that's the one. They got a 50 million pound uranium deal to provide cities. Oh, Robin Hood still going up. I forgot about them. Coin pop. Yeah, we just had that one up. That one's going there. Watch if Bitcoin takes off. SMCI on the high as well. Actually I haven't looked at Marvel yet. Nvidia wise. Is this after hours? Yeah, Nvidia looks like it's dancing around. Marvel might break out. That one's actually holding. So out of all of them that held two standard deviations. This was pricing in like 12 though. So it's still one standard deviation but it's not bad, huh? Oh and then intel dumped again. That was from pre market. A lot of wild moves from pre market. CRM climbing. Yeah, the plays are coming back up but it's still a little again it was up a lot in the morning. All of them. Octa where's actually PSTG. Yeah, even PSTG was up another 10%. Workday breaking out. There's Marvel. I kind of D the mar. Damn. So there's like out of the money marvels that are up like a thousand percent but they're really cheap. But then they just smash the ask on that one. They changed that one. So watch out for that. But Marvel's breaking out. That one's good again. I was telling you I was hesitant on it but when this thing moves man, it actually really moves. So that's already up 19. You post your plays right here. You can post them on the watch list too. But you have a chat fact. So if you do post the play just here in the chat it will stay to your name. Brian Thompson shot near Hilton Hotel Suspect still at large. CEO United Healthcare they're reporting it. It's United Healthcare Group CEO killed outside a Manhattan hotel. So again down the news agencies are reporting it. That was from the morning again apparently was shot near his hotel. So it was not at the investor day but it was right before their investor day. And then Microsoft breaking out here again. Watch Marvel but the plays are kind of all over. So good luck man. Where's workday? BTDR Google on the high it is two different companies but I.\n",
            "Videos saved to test.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "import random\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "YOUTUBE_API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"\n",
        "channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # The channel ID you provided\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "# Fetch random 5 videos from the channel\n",
        "def get_random_channel_video_links(channel_id, num_videos=5):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while len(video_links) < num_videos:  # Stop after 5 videos\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_status = youtube.videos().list(\n",
        "                    part=\"snippet, liveStreamingDetails\",\n",
        "                    id=video_id\n",
        "                ).execute()\n",
        "\n",
        "                # Skip live or upcoming videos\n",
        "                live_status = video_status[\"items\"][0].get(\"liveStreamingDetails\", {}).get(\"liveStatus\", None)\n",
        "                if live_status in [\"upcoming\", \"live\"]:\n",
        "                    continue\n",
        "\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "                if len(video_links) >= num_videos:\n",
        "                    break\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    available_transcripts = []\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            available_transcripts.append((link, transcript))\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return available_transcripts, failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    downloaded_files = []\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([link])\n",
        "            print(f\"Audio downloaded successfully for video: {link}\")\n",
        "            downloaded_files.append(link)\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "    return downloaded_files\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Step 5: Save videos in a zip file\n",
        "def save_videos_to_zip(video_files, zip_filename):\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for video_file in video_files:\n",
        "            zipf.write(video_file, os.path.basename(video_file))\n",
        "    print(f\"Videos saved to {zip_filename}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Step 1: Get random 5 video links from the channel\n",
        "    video_links = get_random_channel_video_links(channel_id)\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    if len(video_links) < 5:\n",
        "        print(\"Not enough videos found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Variables to track whether AssemblyAI has been used\n",
        "    assembly_ai_used = False\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    available_transcripts = []\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            available_transcripts.append((link, transcript))\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    # Step 3: Ensure at least one video is processed with AssemblyAI\n",
        "    if failed_videos:\n",
        "        # Pick the first failed video and transcribe using AssemblyAI\n",
        "        assembly_ai_video = failed_videos.pop(0)\n",
        "        audio_file = download_audio([assembly_ai_video])[0]\n",
        "        transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_file)\n",
        "        if transcript:\n",
        "            available_transcripts.append((assembly_ai_video, transcript))\n",
        "            assembly_ai_used = True\n",
        "            print(f\"AssemblyAI transcription completed for {assembly_ai_video}\")\n",
        "\n",
        "    # Step 4: Save the transcripts\n",
        "    for video_link, transcript in available_transcripts:\n",
        "        transcript_filename = f\"transcripts/{video_link.split('=')[1]}.txt\"\n",
        "        os.makedirs(os.path.dirname(transcript_filename), exist_ok=True)\n",
        "        with open(transcript_filename, 'w') as f:\n",
        "            for entry in transcript:\n",
        "                f.write(f\"{entry['start']}: {entry['text']}\\n\")\n",
        "        print(f\"Transcript saved for video: {video_link}\")\n",
        "\n",
        "    # Step 5: Save the processed videos to a zip file\n",
        "    video_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "    if video_files:\n",
        "        save_videos_to_zip(video_files, \"test.zip\")\n",
        "\n",
        "    print(\"Finished processing 5 videos. Exiting...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "Igmaixj3aFlU",
        "outputId": "22b4b728-c5d8-43bc-d12c-98be8752edb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=mdGpEqki8Lk', 'https://www.youtube.com/watch?v=AU_m12Nuk4k', 'https://www.youtube.com/watch?v=izZ0ZzsJ82A', 'https://www.youtube.com/watch?v=Og142I-11hw', 'https://www.youtube.com/watch?v=u7uOUHbhqXw']\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=AU_m12Nuk4k\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=izZ0ZzsJ82A\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Og142I-11hw\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "[youtube] mdGpEqki8Lk: Downloading webpage\n",
            "[youtube] mdGpEqki8Lk: Downloading ios player API JSON\n",
            "[youtube] mdGpEqki8Lk: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=mdGpEqki8Lk: ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b97ba8207112>\u001b[0m in \u001b[0;36m<cell line: 198>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-b97ba8207112>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Pick the first failed video and transcribe using AssemblyAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0massembly_ai_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfailed_videos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massembly_ai_video\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASSEMBLYAI_API_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "import random\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "YOUTUBE_API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"\n",
        "channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # The channel ID you provided\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)\n",
        "FAILED_VIDEOS_FILE = \"failed_videos.txt\"\n",
        "\n",
        "# Fetch random 5 videos from the channel\n",
        "def get_random_channel_video_links(channel_id, num_videos=5):\n",
        "    try:\n",
        "        # Fetch the channel's uploads playlist ID\n",
        "        response = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        ).execute()\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos in the uploads playlist\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while len(video_links) < num_videos:  # Stop after 5 videos\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_status = youtube.videos().list(\n",
        "                    part=\"snippet, liveStreamingDetails\",\n",
        "                    id=video_id\n",
        "                ).execute()\n",
        "\n",
        "                # Skip live or upcoming videos\n",
        "                live_status = video_status[\"items\"][0].get(\"liveStreamingDetails\", {}).get(\"liveStatus\", None)\n",
        "                if live_status in [\"upcoming\", \"live\"]:\n",
        "                    continue\n",
        "\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "                if len(video_links) >= num_videos:\n",
        "                    break\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "def fetch_transcripts(video_links):\n",
        "    available_transcripts = []\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            available_transcripts.append((link, transcript))\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return available_transcripts, failed_videos\n",
        "\n",
        "# Step 3: Download audio files for failed videos\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    downloaded_files = []\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([link])\n",
        "            print(f\"Audio downloaded successfully for video: {link}\")\n",
        "            downloaded_files.append(link)\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "    return downloaded_files\n",
        "\n",
        "# Step 4: Transcribe audio using AssemblyAI\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    # Upload audio file\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    # Request transcription\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Step 5: Save videos in a zip file\n",
        "def save_videos_to_zip(video_files, zip_filename):\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for video_file in video_files:\n",
        "            zipf.write(video_file, os.path.basename(video_file))\n",
        "    print(f\"Videos saved to {zip_filename}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Step 1: Get random 5 video links from the channel\n",
        "    video_links = get_random_channel_video_links(channel_id)\n",
        "    print(f\"Processing videos: {video_links}\")\n",
        "\n",
        "    if len(video_links) < 5:\n",
        "        print(\"Not enough videos found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Variables to track whether AssemblyAI has been used\n",
        "    assembly_ai_used = False\n",
        "\n",
        "    # Step 2: Fetch transcripts using YouTubeTranscriptApi\n",
        "    available_transcripts = []\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            available_transcripts.append((link, transcript))\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    # Step 3: Ensure at least one video is processed with AssemblyAI\n",
        "    if failed_videos:\n",
        "        # Pick the first failed video and transcribe using AssemblyAI\n",
        "        assembly_ai_video = failed_videos.pop(0)\n",
        "        # Check if the video is live or upcoming before attempting to download\n",
        "        video_id = assembly_ai_video.split(\"v=\")[1]\n",
        "        video_status = youtube.videos().list(\n",
        "            part=\"snippet, liveStreamingDetails\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "\n",
        "        live_status = video_status[\"items\"][0].get(\"liveStreamingDetails\", {}).get(\"liveStatus\", None)\n",
        "\n",
        "        if live_status not in [\"upcoming\", \"live\"]:  # Only process if it's not live\n",
        "            audio_file = download_audio([assembly_ai_video])\n",
        "            if audio_file:\n",
        "                transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_file[0])\n",
        "                if transcript:\n",
        "                    available_transcripts.append((assembly_ai_video, transcript))\n",
        "                    assembly_ai_used = True\n",
        "                    print(f\"AssemblyAI transcription completed for {assembly_ai_video}\")\n",
        "        else:\n",
        "            print(f\"Skipping live or scheduled video: {assembly_ai_video}\")\n",
        "\n",
        "    # Step 4: Save the transcripts\n",
        "    for video_link, transcript in available_transcripts:\n",
        "        transcript_filename = f\"transcripts/{video_link.split('=')[1]}.txt\"\n",
        "        os.makedirs(os.path.dirname(transcript_filename), exist_ok=True)\n",
        "        with open(transcript_filename, 'w') as f:\n",
        "            for entry in transcript:\n",
        "                f.write(f\"{entry['start']}: {entry['text']}\\n\")\n",
        "        print(f\"Transcript saved for video: {video_link}\")\n",
        "\n",
        "    # Step 5: Save the processed videos to a zip file\n",
        "    video_files = [f\"downloads/{f}\" for f in os.listdir(\"downloads\") if f.endswith(\".mp3\")]\n",
        "    if video_files:\n",
        "        save_videos_to_zip(video_files, \"test.zip\")\n",
        "\n",
        "    print(\"Finished processing 5 videos. Exiting...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABWngxOJaa3g",
        "outputId": "4601f3fb-0b3d-4095-f3c8-64f35f2a206f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=mdGpEqki8Lk', 'https://www.youtube.com/watch?v=AU_m12Nuk4k', 'https://www.youtube.com/watch?v=izZ0ZzsJ82A', 'https://www.youtube.com/watch?v=Og142I-11hw', 'https://www.youtube.com/watch?v=u7uOUHbhqXw']\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=AU_m12Nuk4k\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=izZ0ZzsJ82A\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=Og142I-11hw\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=mdGpEqki8Lk\n",
            "[youtube] mdGpEqki8Lk: Downloading webpage\n",
            "[youtube] mdGpEqki8Lk: Downloading ios player API JSON\n",
            "[youtube] mdGpEqki8Lk: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading audio for https://www.youtube.com/watch?v=mdGpEqki8Lk: ERROR: [youtube] mdGpEqki8Lk: This live event will begin in 3 hours.\n",
            "Transcript saved for video: https://www.youtube.com/watch?v=AU_m12Nuk4k\n",
            "Transcript saved for video: https://www.youtube.com/watch?v=izZ0ZzsJ82A\n",
            "Transcript saved for video: https://www.youtube.com/watch?v=Og142I-11hw\n",
            "Videos saved to test.zip\n",
            "Finished processing 5 videos. Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"  # Replace with your valid YouTube Data API v3 key\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"  # Replace with your AssemblyAI API key\n",
        "channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # Replace with your actual channel ID\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "# Output file\n",
        "OUTPUT_ZIP = \"test.zip\"\n",
        "\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        response = youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while True:\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "def fetch_transcripts(video_links):\n",
        "    available_transcripts = []\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "            available_transcripts.append((link, transcript))\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return available_transcripts, failed_videos\n",
        "\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    downloaded_files = []\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info_dict = ydl.extract_info(link, download=True)\n",
        "                audio_file = ydl.prepare_filename(info_dict)\n",
        "                downloaded_files.append(audio_file)\n",
        "                print(f\"Audio downloaded successfully for video: {link}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "    return downloaded_files\n",
        "\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def save_to_zip(files):\n",
        "    with zipfile.ZipFile(OUTPUT_ZIP, 'w') as zipf:\n",
        "        for file in files:\n",
        "            zipf.write(file, os.path.basename(file))\n",
        "    print(f\"Files saved to {OUTPUT_ZIP}\")\n",
        "\n",
        "def main():\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "\n",
        "    # Select 5 random videos\n",
        "    random_videos = random.sample(video_links, 5)\n",
        "    print(f\"Processing videos: {random_videos}\")\n",
        "\n",
        "    # Fetch transcripts and find videos needing AssemblyAI\n",
        "    available_transcripts, failed_videos = fetch_transcripts(random_videos)\n",
        "\n",
        "    # Process AssemblyAI if any failed video exists\n",
        "    if failed_videos:\n",
        "        # Ensure one video is processed via AssemblyAI\n",
        "        assembly_ai_video = failed_videos.pop(0)\n",
        "        audio_file = download_audio([assembly_ai_video])[0]\n",
        "        transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_file)\n",
        "        if transcript:\n",
        "            print(f\"Transcription completed via AssemblyAI for {assembly_ai_video}\")\n",
        "            available_transcripts.append((assembly_ai_video, transcript))\n",
        "\n",
        "    # Save all transcripts and videos into a zip\n",
        "    transcript_files = []\n",
        "    for video_link, transcript in available_transcripts:\n",
        "        transcript_file = f\"transcript_{video_link.split('v=')[1]}.txt\"\n",
        "        with open(transcript_file, 'w') as f:\n",
        "            f.write(\"\\n\".join([entry['text'] for entry in transcript]))\n",
        "        transcript_files.append(transcript_file)\n",
        "\n",
        "    # Save audio files if downloaded\n",
        "    audio_files = []\n",
        "    if failed_videos:\n",
        "        audio_files = download_audio(failed_videos)\n",
        "\n",
        "    save_to_zip(transcript_files + audio_files)\n",
        "\n",
        "    print(f\"Finished processing {len(transcript_files)} transcripts and {len(audio_files)} audio files.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "GMAh_zbObbWO",
        "outputId": "db90b8a4-6122-4c97-b88f-f2c19e80ad43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=9B3xJPk5_Q4', 'https://www.youtube.com/watch?v=VvB4c42_guw', 'https://www.youtube.com/watch?v=gnPB8FOmA-0', 'https://www.youtube.com/watch?v=p-8AXE35zuY', 'https://www.youtube.com/watch?v=gczxEUKTSYo']\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=9B3xJPk5_Q4\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=VvB4c42_guw\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=gnPB8FOmA-0\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=p-8AXE35zuY\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=gczxEUKTSYo\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=VvB4c42_guw\n",
            "[youtube] VvB4c42_guw: Downloading webpage\n",
            "[youtube] VvB4c42_guw: Downloading ios player API JSON\n",
            "[youtube] VvB4c42_guw: Downloading mweb player API JSON\n",
            "[youtube] VvB4c42_guw: Downloading m3u8 information\n",
            "[info] VvB4c42_guw: Downloading 1 format(s): 251\n",
            "[download] Destination: downloads/TRADING BIDEN STIMULUS - DOW & SPY Live Trading, Robinhood, Stock Picks, Day Trading & STOCK NEWS.webm\n",
            "[download] 100% of  325.34MiB in 00:00:24 at 13.43MiB/s  \n",
            "[ExtractAudio] Destination: downloads/TRADING BIDEN STIMULUS - DOW & SPY Live Trading, Robinhood, Stock Picks, Day Trading & STOCK NEWS.mp3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-034672aea101>\u001b[0m in \u001b[0;36m<cell line: 158>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-034672aea101>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Ensure one video is processed via AssemblyAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0massembly_ai_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfailed_videos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massembly_ai_video\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASSEMBLYAI_API_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-034672aea101>\u001b[0m in \u001b[0;36mdownload_audio\u001b[0;34m(video_links)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0myt_dlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYoutubeDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydl_opts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mydl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0minfo_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mydl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mydl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mdownloaded_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mextract_info\u001b[0;34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[0m\n\u001b[1;32m   1611\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mExistingVideoReached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__extract_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_info_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m             \u001b[0mextractors_restricted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allowed_extractors'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCookieLoadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadCancelled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPagedList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36m__extract_info\u001b[0;34m(self, url, ie, download, extra_info, process)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mie_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_ie_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mie_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mie_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mprocess_ie_result\u001b[0;34m(self, ie_result, download, extra_info)\u001b[0m\n\u001b[1;32m   1837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'video'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_extra_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mie_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mie_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_video_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mie_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_pending_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mie_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0madditional_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mie_result\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'additional_urls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mprocess_video_result\u001b[0;34m(self, info_dict, download)\u001b[0m\n\u001b[1;32m   3009\u001b[0m                 \u001b[0mdownloaded_formats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3012\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mMaxDownloadsReached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m                     \u001b[0mmax_downloads_reached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_UnsafeExtensionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             self.report_error(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mprocess_info\u001b[0;34m(self, info_dict)\u001b[0m\n\u001b[1;32m   3555\u001b[0m                 \u001b[0mfixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m                     \u001b[0mreplace_info_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_to_move\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mPostProcessingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Postprocessing: {err}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mpost_process\u001b[0;34m(self, filename, info, files_to_move)\u001b[0m\n\u001b[1;32m   3739\u001b[0m         \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filepath'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3740\u001b[0m         \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__files_to_move'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles_to_move\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3741\u001b[0;31m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_all_pps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post_process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_pps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__postprocessors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3742\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMoveFilesAfterDownloadPP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__files_to_move'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mrun_all_pps\u001b[0;34m(self, key, info, additional_pps)\u001b[0m\n\u001b[1;32m   3721\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forceprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madditional_pps\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3723\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3724\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/YoutubeDL.py\u001b[0m in \u001b[0;36mrun_pp\u001b[0;34m(self, pp, infodict)\u001b[0m\n\u001b[1;32m   3699\u001b[0m             \u001b[0minfodict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__files_to_move'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3700\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3701\u001b[0;31m             \u001b[0mfiles_to_delete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfodict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfodict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3702\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPostProcessingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3703\u001b[0m             \u001b[0;31m# Must be True and not 'only_download'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/postprocessor/common.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, info, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0minfo_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_infodict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hook_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'started'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/postprocessor/common.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, info)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     else 'images')\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Skipping {format_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/postprocessor/ffmpeg.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, information)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Destination: {new_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_ffmpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macodec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmore_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/postprocessor/ffmpeg.py\u001b[0m in \u001b[0;36mrun_ffmpeg\u001b[0;34m(self, path, out_path, codec, more_opts)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'-vn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0macodec_opts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmore_opts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mFFmpegPostProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_ffmpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFFmpegPostProcessorError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mPostProcessingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'audio conversion failed: {err.msg}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/postprocessor/ffmpeg.py\u001b[0m in \u001b[0;36mrun_ffmpeg\u001b[0;34m(self, path, out_path, opts, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_ffmpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_ffmpeg_multiple_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/postprocessor/ffmpeg.py\u001b[0m in \u001b[0;36mrun_ffmpeg_multiple_files\u001b[0;34m(self, input_paths, out_path, opts, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_ffmpeg_multiple_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         return self.real_run_ffmpeg(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             [(out_path, opts)], **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/postprocessor/ffmpeg.py\u001b[0m in \u001b[0;36mreal_run_ffmpeg\u001b[0;34m(self, input_path_opts, output_path_opts, expected_retcodes)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'ffmpeg command line: {shell_quote(cmd)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         _, stderr, returncode = Popen.run(\n\u001b[0m\u001b[1;32m    364\u001b[0m             cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturncode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_retcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/utils/_utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cls, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__text_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_or_kill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstdout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yt_dlp/utils/_utils.py\u001b[0m in \u001b[0;36mcommunicate_or_kill\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcommunicate_or_kill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"  # Replace with your valid YouTube Data API v3 key\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"  # Replace with your AssemblyAI API key\n",
        "channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # Replace with your actual channel ID\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "# Output file\n",
        "OUTPUT_ZIP = \"test.zip\"\n",
        "\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        response = youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while True:\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "def fetch_transcripts(video_links):\n",
        "    available_transcripts = []\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "            available_transcripts.append((link, transcript))\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return available_transcripts, failed_videos\n",
        "\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    downloaded_files = []\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info_dict = ydl.extract_info(link, download=True)\n",
        "                audio_file = ydl.prepare_filename(info_dict)\n",
        "                downloaded_files.append(audio_file)\n",
        "                print(f\"Audio downloaded successfully for video: {link}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "    return downloaded_files\n",
        "\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        response = requests.post(upload_url, headers=headers, data=f)\n",
        "        audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "    transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "    data = {\"audio_url\": audio_url}\n",
        "    transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "    transcript_id = transcript_response.json()[\"id\"]\n",
        "    status = \"processing\"\n",
        "\n",
        "    while status == \"processing\":\n",
        "        result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "        status = result.json()[\"status\"]\n",
        "\n",
        "    if status == \"completed\":\n",
        "        return result.json()[\"text\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def save_to_zip(files):\n",
        "    with zipfile.ZipFile(OUTPUT_ZIP, 'w') as zipf:\n",
        "        for file in files:\n",
        "            zipf.write(file, os.path.basename(file))\n",
        "    print(f\"Files saved to {OUTPUT_ZIP}\")\n",
        "\n",
        "def main():\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "\n",
        "    # Select 2 random videos\n",
        "    random_videos = random.sample(video_links, 2)\n",
        "    print(f\"Processing videos: {random_videos}\")\n",
        "\n",
        "    # Fetch transcripts and find videos needing AssemblyAI\n",
        "    available_transcripts, failed_videos = fetch_transcripts(random_videos)\n",
        "\n",
        "    # Process AssemblyAI if any failed video exists\n",
        "    if failed_videos:\n",
        "        # Ensure one video is processed via AssemblyAI\n",
        "        assembly_ai_video = failed_videos.pop(0)\n",
        "        audio_file = download_audio([assembly_ai_video])[0]\n",
        "        transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_file)\n",
        "        if transcript:\n",
        "            print(f\"Transcription completed via AssemblyAI for {assembly_ai_video}\")\n",
        "            available_transcripts.append((assembly_ai_video, transcript))\n",
        "\n",
        "    # Save all transcripts and videos into a zip\n",
        "    transcript_files = []\n",
        "    for video_link, transcript in available_transcripts:\n",
        "        transcript_file = f\"transcript_{video_link.split('v=')[1]}.txt\"\n",
        "        with open(transcript_file, 'w') as f:\n",
        "            f.write(\"\\n\".join([entry['text'] for entry in transcript]))\n",
        "        transcript_files.append(transcript_file)\n",
        "\n",
        "    # Save audio files if downloaded\n",
        "    audio_files = []\n",
        "    if failed_videos:\n",
        "        audio_files = download_audio(failed_videos)\n",
        "\n",
        "    save_to_zip(transcript_files + audio_files)\n",
        "\n",
        "    print(f\"Finished processing {len(transcript_files)} transcripts and {len(audio_files)} audio files.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "DECAsqn_cdC9",
        "outputId": "47dc4373-1f10-46bd-ff8b-7b6a0f1303ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=VzgrpWPzK6U', 'https://www.youtube.com/watch?v=nBF7mLbw_V4']\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=VzgrpWPzK6U\n",
            "Transcript fetched successfully for video: https://www.youtube.com/watch?v=nBF7mLbw_V4\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=VzgrpWPzK6U\n",
            "[youtube] VzgrpWPzK6U: Downloading webpage\n",
            "[youtube] VzgrpWPzK6U: Downloading ios player API JSON\n",
            "[youtube] VzgrpWPzK6U: Downloading mweb player API JSON\n",
            "[youtube] VzgrpWPzK6U: Downloading m3u8 information\n",
            "[info] VzgrpWPzK6U: Downloading 1 format(s): 251\n",
            "[download] Destination: downloads/STOCKS & CRYPTO OPEN STRONG! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.webm\n",
            "[download] 100% of  335.10MiB in 00:00:29 at 11.51MiB/s  \n",
            "[ExtractAudio] Destination: downloads/STOCKS & CRYPTO OPEN STRONG! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.mp3\n",
            "Deleting original file downloads/STOCKS & CRYPTO OPEN STRONG! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.webm (pass -k to keep)\n",
            "Audio downloaded successfully for video: https://www.youtube.com/watch?v=VzgrpWPzK6U\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'downloads/STOCKS & CRYPTO OPEN STRONG! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.webm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-629b6d551ac7>\u001b[0m in \u001b[0;36m<cell line: 158>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-629b6d551ac7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0massembly_ai_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfailed_videos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massembly_ai_video\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASSEMBLYAI_API_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Transcription completed via AssemblyAI for {assembly_ai_video}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-629b6d551ac7>\u001b[0m in \u001b[0;36mtranscribe_audio\u001b[0;34m(assemblyai_api_key, audio_file)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mupload_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://api.assemblyai.com/v2/upload\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0maudio_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upload_url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'downloads/STOCKS & CRYPTO OPEN STRONG! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.webm'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import requests\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up your API keys and constants\n",
        "API_KEY = \"AIzaSyD3yF_r1J0DkcbKNtTBwzQlmMN_LWSWRlk\"  # Replace with your valid YouTube Data API v3 key\n",
        "ASSEMBLYAI_API_KEY = \"d773b67f986746528b961cd5772004b1\"  # Replace with your AssemblyAI API key\n",
        "channel_id = \"UCsfp0zw1hNxpy_wDig8oExA\"  # Replace with your actual channel ID\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "# Output file\n",
        "OUTPUT_ZIP = \"test.zip\"\n",
        "\n",
        "\n",
        "def get_channel_video_links_and_dates(channel_id):\n",
        "    try:\n",
        "        response = youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        video_links = []\n",
        "        next_page_token = None\n",
        "\n",
        "        while True:\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            for item in playlist_response[\"items\"]:\n",
        "                video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "            next_page_token = playlist_response.get(\"nextPageToken\")\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        return video_links\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Error fetching channel videos: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def fetch_transcripts(video_links):\n",
        "    available_transcripts = []\n",
        "    failed_videos = []\n",
        "\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        try:\n",
        "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            print(f\"Transcript fetched successfully for video: {link}\")\n",
        "            available_transcripts.append((link, transcript))\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(f\"Transcript not available for video: {link}\")\n",
        "            failed_videos.append(link)\n",
        "\n",
        "    return available_transcripts, failed_videos\n",
        "\n",
        "\n",
        "def download_audio(video_links):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
        "        'noplaylist': True,\n",
        "    }\n",
        "\n",
        "    downloaded_files = []\n",
        "\n",
        "    for link in video_links:\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info_dict = ydl.extract_info(link, download=True)\n",
        "                base_filename = ydl.prepare_filename(info_dict)\n",
        "                mp3_file = base_filename.rsplit('.', 1)[0] + '.mp3'\n",
        "\n",
        "                if os.path.exists(mp3_file):\n",
        "                    downloaded_files.append(mp3_file)\n",
        "                    print(f\"Audio downloaded successfully for video: {link}\")\n",
        "                else:\n",
        "                    print(f\"Error: Converted MP3 file not found for {link}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio for {link}: {e}\")\n",
        "\n",
        "    return downloaded_files\n",
        "\n",
        "\n",
        "def transcribe_audio(assemblyai_api_key, audio_file):\n",
        "    headers = {\"authorization\": assemblyai_api_key}\n",
        "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
        "\n",
        "    try:\n",
        "        with open(audio_file, \"rb\") as f:\n",
        "            response = requests.post(upload_url, headers=headers, data=f)\n",
        "            audio_url = response.json()[\"upload_url\"]\n",
        "\n",
        "        transcript_url = \"https://api.assemblyai.com/v2/transcript\"\n",
        "        data = {\"audio_url\": audio_url}\n",
        "        transcript_response = requests.post(transcript_url, headers=headers, json=data)\n",
        "\n",
        "        transcript_id = transcript_response.json()[\"id\"]\n",
        "        status = \"processing\"\n",
        "\n",
        "        while status == \"processing\":\n",
        "            result = requests.get(f\"{transcript_url}/{transcript_id}\", headers=headers)\n",
        "            status = result.json()[\"status\"]\n",
        "\n",
        "        if status == \"completed\":\n",
        "            return result.json()[\"text\"]\n",
        "        else:\n",
        "            print(f\"Transcription failed for {audio_file}: {status}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing audio: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_to_zip(files):\n",
        "    with zipfile.ZipFile(OUTPUT_ZIP, 'w') as zipf:\n",
        "        for file in files:\n",
        "            zipf.write(file, os.path.basename(file))\n",
        "    print(f\"Files saved to {OUTPUT_ZIP}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    video_links = get_channel_video_links_and_dates(channel_id)\n",
        "\n",
        "    # Select 2 random videos\n",
        "    random_videos = random.sample(video_links, 2)\n",
        "    print(f\"Processing videos: {random_videos}\")\n",
        "\n",
        "    # Fetch transcripts and find videos needing AssemblyAI\n",
        "    available_transcripts, failed_videos = fetch_transcripts(random_videos)\n",
        "\n",
        "    # Process AssemblyAI if any failed video exists\n",
        "    if failed_videos:\n",
        "        # Ensure one video is processed via AssemblyAI\n",
        "        assembly_ai_video = failed_videos.pop(0)\n",
        "        audio_files = download_audio([assembly_ai_video])\n",
        "\n",
        "        if audio_files:\n",
        "            transcript = transcribe_audio(ASSEMBLYAI_API_KEY, audio_files[0])\n",
        "            if transcript:\n",
        "                print(f\"Transcription completed via AssemblyAI for {assembly_ai_video}\")\n",
        "                available_transcripts.append((assembly_ai_video, transcript))\n",
        "\n",
        "    # Save all transcripts and videos into a zip\n",
        "    transcript_files = []\n",
        "    for video_link, transcript in available_transcripts:\n",
        "        video_id = video_link.split('v=')[1]\n",
        "        transcript_file = f\"transcript_{video_id}.txt\"\n",
        "        with open(transcript_file, 'w') as f:\n",
        "            if isinstance(transcript, list):\n",
        "                f.write(\"\\n\".join([entry['text'] for entry in transcript]))\n",
        "            else:\n",
        "                f.write(transcript)\n",
        "        transcript_files.append(transcript_file)\n",
        "\n",
        "    # Save audio files if downloaded\n",
        "    audio_files = []\n",
        "    if failed_videos:\n",
        "        audio_files = download_audio(failed_videos)\n",
        "\n",
        "    save_to_zip(transcript_files + audio_files)\n",
        "\n",
        "    print(f\"Finished processing {len(transcript_files)} transcripts and {len(audio_files)} audio files.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17pHlNnZhO2u",
        "outputId": "c04e336c-bf36-4d9f-cf22-f8576a54b7b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing videos: ['https://www.youtube.com/watch?v=S2aNk4po3AE', 'https://www.youtube.com/watch?v=lY0mUvycAWg']\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=S2aNk4po3AE\n",
            "Transcript not available for video: https://www.youtube.com/watch?v=lY0mUvycAWg\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=S2aNk4po3AE\n",
            "[youtube] S2aNk4po3AE: Downloading webpage\n",
            "[youtube] S2aNk4po3AE: Downloading ios player API JSON\n",
            "[youtube] S2aNk4po3AE: Downloading mweb player API JSON\n",
            "[youtube] S2aNk4po3AE: Downloading m3u8 information\n",
            "[info] S2aNk4po3AE: Downloading 1 format(s): 251\n",
            "[download] Destination: downloads/STOCKS GAP UP!!! – Live Trading, Robinhood Options, Day Trading & STOCK MARKET NEWS TODAY.webm\n",
            "[download] 100% of  325.11MiB in 00:00:24 at 13.41MiB/s  \n",
            "[ExtractAudio] Destination: downloads/STOCKS GAP UP!!! – Live Trading, Robinhood Options, Day Trading & STOCK MARKET NEWS TODAY.mp3\n",
            "Deleting original file downloads/STOCKS GAP UP!!! – Live Trading, Robinhood Options, Day Trading & STOCK MARKET NEWS TODAY.webm (pass -k to keep)\n",
            "Audio downloaded successfully for video: https://www.youtube.com/watch?v=S2aNk4po3AE\n",
            "Transcription completed via AssemblyAI for https://www.youtube.com/watch?v=S2aNk4po3AE\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=lY0mUvycAWg\n",
            "[youtube] lY0mUvycAWg: Downloading webpage\n",
            "[youtube] lY0mUvycAWg: Downloading ios player API JSON\n",
            "[youtube] lY0mUvycAWg: Downloading mweb player API JSON\n",
            "[youtube] lY0mUvycAWg: Downloading m3u8 information\n",
            "[info] lY0mUvycAWg: Downloading 1 format(s): 251\n",
            "[download] Destination: downloads/TRADING DIDI IPO LIVE! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.webm\n",
            "[download] 100% of  340.81MiB in 00:00:53 at 6.40MiB/s   \n",
            "[ExtractAudio] Destination: downloads/TRADING DIDI IPO LIVE! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.mp3\n",
            "Deleting original file downloads/TRADING DIDI IPO LIVE! - Live Trading, DOW & S&P, Stock Picks, Day Trading & STOCK NEWS.webm (pass -k to keep)\n",
            "Audio downloaded successfully for video: https://www.youtube.com/watch?v=lY0mUvycAWg\n",
            "Files saved to test.zip\n",
            "Finished processing 1 transcripts and 1 audio files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vY7DRWitfNSl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}